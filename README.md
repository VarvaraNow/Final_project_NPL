# Final_project_NPL
Компания работает  в e-commerce проекте. Бизнес-юнит в процессе обсуждения, закупать ли кликстрим логов посещения некоторого портала другого магазина.

**Цель проекта:** Сформировать понимание, закупать ли бизнес-юниту кликстрим логов посещения некоторого портала другого магазина, что повысит конкуретоспособность компании на рынке.

**Задачи проекта:**
- Создать таблицы в Clickhouse
- Загрузить данные в таблицы Clickhouse с помощью Airflow из Яндекс облака
- Для аналитики сформировать несколько графиков в Power BI

Первоначально данные загружаются в следующие таблицы:
* browser_events — данные с информацией о просмотрах браузера
* device_events — данные об устройствах, с которых пользователи пользовались сайтом
* geo_events — данные о локации пользователя
* location_events —  данные о положении пользователя на сайте и информации о том, откуда пользователь попал на страницу

Информация о факте покупки и количеству покупок определяется по столбцу "page_url_path" в таблице "location_events" по значению "/confirmation"- означает, что покупка подтверждена.

Структура данных в Power BI выглядит следующим образом: ![image](https://github.com/VarvaraNow/Final_project_NPL/assets/116558491/b9d66101-bac2-4fb0-ba9f-7e3782bd0156)



С графиками можно ознакомиться по [ссылке](https://app.powerbi.com/view?r=eyJrIjoiYmZkYTRiZmItZmRiYi00ZTZiLTliNjEtNDA1NDBkY2I0YmM1IiwidCI6IjEzN2E2YTYzLWU3OWUtNDkzMS1hZjBjLWVlYTIzMmM0MWFmNyIsImMiOjl9)


Для выгрузки данных из яндекс облака из добавления в кликхаус используем AirFlow. Создаем скрипт, который находится в файле "lab_06.py", работает ежечасно.
При первом включении полностью записывает данные с 10.04.2024 23:00:00 в БД.
Используемые библиотеки и их версии записаны в "requirements.txt"
Для полной очистки кликхаус таблиц мануально запускается даг "truncate_clickhouse", который находится в файле "lab_06_truncate.py"

Для работы скриптов используется config_lab06.json со следующими параметрами:
- click_ip (str) - IP для подключению к кликхаусу
- click_port (str/int) - Порт для подключения к кликхаусу
- s3_url (str) - URL ссылка на облако
- s3_region (str) - Регион подключения
- s3_key_id (str) - ID ключа сервисного аккаунта
- s3_key_access (str) - Токен сервисного аккаунта (секретный ключ)
- list_tables (list) - Список наименований таблиц, которые скачиваем из облака и грузим в кликхаус
